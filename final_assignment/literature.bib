@online{StatistischesBundesamt2021,
    title = {{Verzeichnis der Krankenhäuser und Vorsorge- oder Rehabilitationseinrichtungen in Deutschland 2021}}, 
    author = {{Statistisches Bundesamt (Destatis)}},
    year = {2021},
    url = {https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Krankenhaeuser/Publikationen/Downloads-Krankenhaeuser/krankenhausverzeichnis-3500100217005.html},
    addendum = {"(accessed: 2024-02-17)"}
}

@article{tiemann2009effects,
  title={Effects of ownership on hospital efficiency in Germany},
  author={Tiemann, Oliver and Schrey{\"o}gg, Jonas},
  journal={Business Research},
  volume={2},
  pages={115--145},
  year={2009},
  publisher={Springer}
}

@inproceedings{han2021impact,
  title={The impact of public reporting schemes and market competition on hospital efficiency},
  author={Han, Ahreum and Lee, Keon-Hyung},
  booktitle={Healthcare},
  volume={9},
  number={8},
  pages={1031},
  year={2021},
  organization={MDPI}
}

@article{lindlbauer2014relationship,
  title={The relationship between hospital specialization and hospital efficiency: do different measures of specialization lead to different results?},
  author={Lindlbauer, Ivonne and Schrey{\"o}gg, Jonas},
  journal={Health care management science},
  volume={17},
  pages={365--378},
  year={2014},
  publisher={Springer}
}

@article{strumann2022can,
  title={Can competition improve hospital quality of care? A difference-in-differences approach to evaluate the effect of increasing quality transparency on hospital quality},
  author={Strumann, Christoph and Geissler, Alexander and Busse, Reinhard and Pross, Christoph},
  journal={The European Journal of Health Economics},
  volume={23},
  number={7},
  pages={1229--1242},
  year={2022},
  publisher={Springer}
}

@article{Mockup,
    title={Picture of mockup},
    author={Eftychia Kourkouraki},
    year={2023}
}

@article{ScreenshotHTB,
  title = {Screenshot of Hospital Transparency Board},
  author = {Hendrik Lüning},
  year = {2024}
}

@article{Architecture,
  title = {Architecture Diagram of Hospital Transparency Board},
  author = {Maximilian Elfers},
  year = {2024}
}

@incollection{Redmon2016,
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2016.91},
isbn = {978-1-4673-8852-8},
keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
pages = {779--788},
publisher = {IEEE},
title = {{You Only Look Once: Unified, Real-Time Object Detection}},
year = {2016}
}

@article{Terven2023,
abstract = {YOLO has become a central real-time object detection system for robotics, driverless cars, and video monitoring applications. We present a comprehensive analysis of YOLO's evolution, examining the innovations and contributions in each iteration from the original YOLO to YOLOv8. We start by describing the standard metrics and postprocessing; then, we discuss the major changes in network architecture and training tricks for each model. Finally, we summarize the essential lessons from YOLO's development and provide a perspective on its future, highlighting potential research directions to enhance real-time object detection systems.},
archivePrefix = {arXiv},
arxivId = {2304.00501},
author = {Terven, Juan and Cordova-Esparza, Diana},
eprint = {2304.00501},
keywords = {computer vision,deep learning,object detection,yolo},
mendeley-groups = {BA Thesis},
pages = {1--33},
title = {{A Comprehensive Review of YOLO: From YOLOv1 to YOLOv8 and Beyond}},
url = {http://arxiv.org/abs/2304.00501},
year = {2023}
}


@article{Zheng2020,
abstract = {Bounding box regression is the crucial step in object detection. In existing methods, while ℓn-norm loss is widely adopted for bounding box regression, it is not tailored to the evaluation metric, i.e., Intersection over Union (IoU). Recently, IoU loss and generalized IoU (GIoU) loss have been proposed to benefit the IoU metric, but still suffer from the problems of slow convergence and inaccurate regression. In this paper, we propose a Distance-IoU (DIoU) loss by incorporating the normalized distance between the predicted box and the target box, which converges much faster in training than IoU and GIoU losses. Furthermore, this paper summarizes three geometric factors in bounding box regression, i.e., overlap area, central point distance and aspect ratio, based on which a Complete IoU (CIoU) loss is proposed, thereby leading to faster convergence and better performance. By incorporating DIoU and CIoU losses into state-of-the-art object detection algorithms, e.g., YOLO v3, SSD and Faster R-CNN, we achieve notable performance gains in terms of not only IoU metric but also GIoU metric. Moreover, DIoU can be easily adopted into non-maximum suppression (NMS) to act as the criterion, further boosting performance improvement.},
archivePrefix = {arXiv},
arxivId = {1911.08287},
author = {Zheng, Zhaohui and Wang, Ping and Liu, Wei and Li, Jinze and Ye, Rongguang and Ren, Dongwei},
doi = {10.1609/aaai.v34i07.6999},
eprint = {1911.08287},
isbn = {9781577358350},
issn = {2159-5399},
journal = {AAAI 2020 - 34th AAAI Conference on Artificial Intelligence},
mendeley-groups = {BA Thesis},
number = {2},
pages = {12993--13000},
title = {{Distance-IoU loss: Faster and better learning for bounding box regression}},
year = {2020}
}
@article{Li2020,
abstract = {One-stage detector basically formulates object detection as dense classification and localization (i.e., bounding box regression). The classification is usually optimized by Focal Loss and the box location is commonly learned under Dirac delta distribution. A recent trend for one-stage detectors is to introduce an individual prediction branch to estimate the quality of localization, where the predicted quality facilitates the classification to improve detection performance. This paper delves into the representations of the above three fundamental elements: quality estimation, classification and localization. Two problems are discovered in existing practices, including (1) the inconsistent usage of the quality estimation and classification between training and inference, and (2) the inflexible Dirac delta distribution for localization. To address the problems, we design new representations for these elements. Specifically, we merge the quality estimation into the class prediction vector to form a joint representation, and use a vector to represent arbitrary distribution of box locations. The improved representations eliminate the inconsistency risk and accurately depict the flexible distribution in real data, but contain continuous labels, which is beyond the scope of Focal Loss. We then propose Generalized Focal Loss (GFL) that generalizes Focal Loss from its discrete form to the continuous version for successful optimization. On COCO test-dev, GFL achieves 45.0 Percent AP using ResNet-101 backbone, surpassing state-of-the-art SAPD (43.5 Percent) and ATSS (43.6 Percent) with higher or comparable inference speed.},
archivePrefix = {arXiv},
arxivId = {2006.04388},
author = {Li, Xiang and Wang, Wenhai and Wu, Lijun and Chen, Shuo and Hu, Xiaolin and Li, Jun and Tang, Jinhui and Yang, Jian},
eprint = {2006.04388},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
mendeley-groups = {BA Thesis},
pages = {1--14},
title = {{Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection}},
volume = {2020-December},
year = {2020}
}


@misc{opencv_about,
mendeley-groups = {BA Thesis},
title = {{About - OpenCV}},
url = {https://opencv.org/about/},
urldate = {2023-07-11}
}

@misc{opencv_release,
mendeley-groups = {BA Thesis},
title = {{Releases - OpenCV}},
url = {https://opencv.org/releases/},
urldate = {2023-07-11}
}