@incollection{Redmon2016,
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2016.91},
isbn = {978-1-4673-8852-8},
keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences},
pages = {779--788},
publisher = {IEEE},
title = {{You Only Look Once: Unified, Real-Time Object Detection}},
year = {2016}
}

@article{Terven2023,
abstract = {YOLO has become a central real-time object detection system for robotics, driverless cars, and video monitoring applications. We present a comprehensive analysis of YOLO's evolution, examining the innovations and contributions in each iteration from the original YOLO to YOLOv8. We start by describing the standard metrics and postprocessing; then, we discuss the major changes in network architecture and training tricks for each model. Finally, we summarize the essential lessons from YOLO's development and provide a perspective on its future, highlighting potential research directions to enhance real-time object detection systems.},
archivePrefix = {arXiv},
arxivId = {2304.00501},
author = {Terven, Juan and Cordova-Esparza, Diana},
eprint = {2304.00501},
keywords = {computer vision,deep learning,object detection,yolo},
mendeley-groups = {BA Thesis},
pages = {1--33},
title = {{A Comprehensive Review of YOLO: From YOLOv1 to YOLOv8 and Beyond}},
url = {http://arxiv.org/abs/2304.00501},
year = {2023}
}


@article{Zheng2020,
abstract = {Bounding box regression is the crucial step in object detection. In existing methods, while ℓn-norm loss is widely adopted for bounding box regression, it is not tailored to the evaluation metric, i.e., Intersection over Union (IoU). Recently, IoU loss and generalized IoU (GIoU) loss have been proposed to benefit the IoU metric, but still suffer from the problems of slow convergence and inaccurate regression. In this paper, we propose a Distance-IoU (DIoU) loss by incorporating the normalized distance between the predicted box and the target box, which converges much faster in training than IoU and GIoU losses. Furthermore, this paper summarizes three geometric factors in bounding box regression, i.e., overlap area, central point distance and aspect ratio, based on which a Complete IoU (CIoU) loss is proposed, thereby leading to faster convergence and better performance. By incorporating DIoU and CIoU losses into state-of-the-art object detection algorithms, e.g., YOLO v3, SSD and Faster R-CNN, we achieve notable performance gains in terms of not only IoU metric but also GIoU metric. Moreover, DIoU can be easily adopted into non-maximum suppression (NMS) to act as the criterion, further boosting performance improvement.},
archivePrefix = {arXiv},
arxivId = {1911.08287},
author = {Zheng, Zhaohui and Wang, Ping and Liu, Wei and Li, Jinze and Ye, Rongguang and Ren, Dongwei},
doi = {10.1609/aaai.v34i07.6999},
eprint = {1911.08287},
isbn = {9781577358350},
issn = {2159-5399},
journal = {AAAI 2020 - 34th AAAI Conference on Artificial Intelligence},
mendeley-groups = {BA Thesis},
number = {2},
pages = {12993--13000},
title = {{Distance-IoU loss: Faster and better learning for bounding box regression}},
year = {2020}
}
@article{Li2020,
abstract = {One-stage detector basically formulates object detection as dense classification and localization (i.e., bounding box regression). The classification is usually optimized by Focal Loss and the box location is commonly learned under Dirac delta distribution. A recent trend for one-stage detectors is to introduce an individual prediction branch to estimate the quality of localization, where the predicted quality facilitates the classification to improve detection performance. This paper delves into the representations of the above three fundamental elements: quality estimation, classification and localization. Two problems are discovered in existing practices, including (1) the inconsistent usage of the quality estimation and classification between training and inference, and (2) the inflexible Dirac delta distribution for localization. To address the problems, we design new representations for these elements. Specifically, we merge the quality estimation into the class prediction vector to form a joint representation, and use a vector to represent arbitrary distribution of box locations. The improved representations eliminate the inconsistency risk and accurately depict the flexible distribution in real data, but contain continuous labels, which is beyond the scope of Focal Loss. We then propose Generalized Focal Loss (GFL) that generalizes Focal Loss from its discrete form to the continuous version for successful optimization. On COCO test-dev, GFL achieves 45.0 Percent AP using ResNet-101 backbone, surpassing state-of-the-art SAPD (43.5 Percent) and ATSS (43.6 Percent) with higher or comparable inference speed.},
archivePrefix = {arXiv},
arxivId = {2006.04388},
author = {Li, Xiang and Wang, Wenhai and Wu, Lijun and Chen, Shuo and Hu, Xiaolin and Li, Jun and Tang, Jinhui and Yang, Jian},
eprint = {2006.04388},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
mendeley-groups = {BA Thesis},
pages = {1--14},
title = {{Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection}},
volume = {2020-December},
year = {2020}
}

@article{wagner2021insect,
  title={Insect decline in the Anthropocene: Death by a thousand cuts},
  author={Wagner, David L and Grames, Eliza M and Forister, Matthew L and Berenbaum, May R and Stopak, David},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={2},
  pages={e2023989118},
  year={2021},
  publisher={National Acad Sciences}
}

@article{li2023,
	author = {given-i=S, given=Songjiang, family=Li and given-i=S, given=Shilong, family=Wang and given-i=P, given=Peng, family=Wang},
	date = {2023-08-13},
	doi = {10.3390/s23167145},
	journaltitle = {Sensors},
	number = {16},
	pages = {7145},
	title = {A Small Object Detection Algorithm for Traffic Signs Based on Improved YOLOv7},
	url = {https://doi.org/10.3390/s23167145},
	volume = {23},
}
@article{mendoza2023,
	author = {given-i=QA, given={Querriel Arvy}, family=Mendoza and given-i=LO, given={L. O.}, family=Pordesimo and given-i=M, given=Mitchell, family=Neilsen and given-i=PR, given={Paul R.}, family=Armstrong and given-i=JF, given={James F.}, family=Campbell and given-i=PT, given={Princess Tiffany}, family=Mendoza},
	date = {2023-03-22},
	doi = {10.3390/ai4010017},
	journaltitle = {AI},
	number = {1},
	pages = {348--360},
	title = {Application of Machine Learning for Insect Monitoring in Grain Facilities},
	url = {https://doi.org/10.3390/ai4010017},
	volume = {4},
}

@misc{opencv_about,
mendeley-groups = {BA Thesis},
title = {{About - OpenCV}},
url = {https://opencv.org/about/},
urldate = {2024-03-28}
}

@misc{opencv_release,
mendeley-groups = {BA Thesis},
title = {{Releases - OpenCV}},
url = {https://opencv.org/releases/},
urldate = {2024-03-28}
}

@misc{ComputerVisionAndMachineLearningSystems,
	author = {{Institute for Geoinformatics}},
	title = {Computer Vision and Machine Learning Systems},
	url = {https://www.uni-muenster.de/Geoinformatics.cvmls/},
	urldate      = {2024-03-15}
}

@misc{PALMA_Wiki_OS,
	author = {{Potthoff, Sebastian}},
	title = {High Performance Computing},
	year = {2024},
	url = {https://confluence.uni-muenster.de/display/HPC/High+Performance+Computing},
	urldate      = {2024-03-28}
}

@misc{PALMA_Uni_Web,
	author = {{n. A.}},
	title = {HPC-System PALMA},
	url = {https://www.uni-muenster.de/CoCoS/Systeme/PALMA.html},
	urldate      = {2024-03-28}
}
@article{Swann2011,
   abstract = {Remote photography and infrared sensors are widely used in the sampling of wildlife populations worldwide, especially for cryptic or elusive species. Guiding the practitioner through the entire process of using camera traps, this book is the first to compile state-of-the-art sampling techniques for the purpose of conducting high-quality science or effective management. Chapters on the evaluation of equipment, field sampling designs, and data analysis methods provide a coherent framework for making inferences about the abundance, species richness, and occupancy of sampled animals. The volume introduces new models that will revolutionize use of camera data to estimate population density, such as the newly developed spatial capture-recapture models. It also includes richly detailed case studies of camera trap work on some of the world's most charismatic, elusive, and endangered wildlife species. Indispensible to wildlife conservationists, ecologists, biologists, and conservation agencies around the world, the text provides a thorough review of the subject as well as a forecast for the use of remote photography in natural resource conservation over the next few decades. © Springer 2011. All rights are reserved.},
   author = {Allan F. O'Connell and James D. Nichols and K. Ullas Karanth},
   doi = {10.1007/978-4-431-99495-4},
   isbn = {9784431994947},
   journal = {Camera Traps in Animal Ecology: Methods and Analyses},
   pages = {1-271},
   publisher = {Springer Japan},
   title = {Camera traps in animal ecology: Methods and analyses},
   year = {2011},
}


@InProceedings{Gebauer_2024_WACV,
    author    = {Gebauer, Eike and Thiele, Sebastian and Ouvrard, Pierre and Sicard, Adrien and Risse, Benjamin},
    title     = {Towards a Dynamic Vision Sensor-Based Insect Camera Trap},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month     = {1},
    year      = {2024},
    pages     = {7157-7166}
}